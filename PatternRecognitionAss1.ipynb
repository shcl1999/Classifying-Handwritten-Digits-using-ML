{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PatternRecognitionAss1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKWG7YCyyUr"
      },
      "source": [
        "# Pattern Recognition Assignment 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVF-TD9sywSz"
      },
      "source": [
        "The data consists of 42,000 examples where each example has 28x28=784 feature values. The first column contains the class label. To read in the data into Python, type (assuming you have saved the data in \"D:/mnist.csv\"):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdIfDSvDyHYb"
      },
      "source": [
        "import pandas as pd\n",
        "mnist_data = pd.read_csv('mnist.csv').values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWRNgsRh6_fu"
      },
      "source": [
        "To display an image of a digit, you can use the function \"imshow\" from the \"matlibplot\" library. For example, to display an image of the example in the first row of the mnist data set, type:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4EYpLM5HzCji",
        "outputId": "d97d80b7-a5dc-4672-954b-5176e037cd56"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels = mnist_data[:, 0]\n",
        "digits = mnist_data[:, 1:]\n",
        "img_size = 28\n",
        "plt.imshow(digits[0].reshape(img_size, img_size))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oB6zTfPhzWvV"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tNaC0HgzZVr"
      },
      "source": [
        "Begin with an exploratory analysis of the data. Can you spot useless variables by looking at their summary statisitcs? Consider the class distribution: what percentage of cases would be classified correctly if we simply predict the majority class? Report any findings from your exploratory analysis that you think are of interest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peLjvsWA9ZSD"
      },
      "source": [
        "### Class distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWFUlD6P1EeQ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "skE3wbX8zfL8",
        "outputId": "6efecadd-6584-49a6-85c0-48ab7dbcfa68"
      },
      "source": [
        "x_label = ['0','1','2','3','4','5','6','7','8','9']\n",
        "y_label_occurences = []\n",
        "\n",
        "for i in range(10):\n",
        "  y_label_occurences.append(np.count_nonzero(labels == i))\n",
        "\n",
        "barplot1 = plt.bar(x_label,y_label_occurences, align = 'center')\n",
        "barplot1[1].set_color('r')\n",
        "plt.title('Occurences per label')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Occurences per label')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO6bd16J5bV1"
      },
      "source": [
        "The percentage of correct predictions if we always predict the majority class (class 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tayAILfG5nNO",
        "outputId": "7ebe06d9-3ecb-49fd-bbd8-6c41ecdb51a3"
      },
      "source": [
        "Correct_Pred_Percentage = (y_label_occurences[1] / sum(y_label_occurences)) * 100\n",
        "\n",
        "print(round(Correct_Pred_Percentage), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3nFda779Q63"
      },
      "source": [
        "### Useless variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNCGcs8A6p4E"
      },
      "source": [
        "df = pd.read_csv(\"mnist.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "syXPzJ3h7U_d",
        "outputId": "7aff3224-e1bd-4bd0-8408-5067c192c2f7"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41995</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41996</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41997</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41998</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41999</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42000 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0          1       0       0       0  ...         0         0         0         0\n",
              "1          0       0       0       0  ...         0         0         0         0\n",
              "2          1       0       0       0  ...         0         0         0         0\n",
              "3          4       0       0       0  ...         0         0         0         0\n",
              "4          0       0       0       0  ...         0         0         0         0\n",
              "...      ...     ...     ...     ...  ...       ...       ...       ...       ...\n",
              "41995      0       0       0       0  ...         0         0         0         0\n",
              "41996      1       0       0       0  ...         0         0         0         0\n",
              "41997      7       0       0       0  ...         0         0         0         0\n",
              "41998      6       0       0       0  ...         0         0         0         0\n",
              "41999      9       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[42000 rows x 785 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2g8lFiU81OQ"
      },
      "source": [
        "Investigate which pixels are never used in ALL data. \n",
        "In other words, where pixel 'x' is always 0."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_used_labels = []\n",
        "\n"
      ],
      "metadata": {
        "id": "upXzOznsAIPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOty_THy8HE9",
        "outputId": "16416c32-4914-4e83-d13e-60d4479573f7"
      },
      "source": [
        "for column in df:\n",
        "    if ((df[column] == 0).all()):\n",
        "      non_used_labels.append(100)\n",
        "      print(column)\n",
        "    else:\n",
        "      non_used_labels.append(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pixel0\n",
            "pixel1\n",
            "pixel2\n",
            "pixel3\n",
            "pixel4\n",
            "pixel5\n",
            "pixel6\n",
            "pixel7\n",
            "pixel8\n",
            "pixel9\n",
            "pixel10\n",
            "pixel11\n",
            "pixel16\n",
            "pixel17\n",
            "pixel18\n",
            "pixel19\n",
            "pixel20\n",
            "pixel21\n",
            "pixel22\n",
            "pixel23\n",
            "pixel24\n",
            "pixel25\n",
            "pixel26\n",
            "pixel27\n",
            "pixel28\n",
            "pixel29\n",
            "pixel30\n",
            "pixel31\n",
            "pixel52\n",
            "pixel53\n",
            "pixel54\n",
            "pixel55\n",
            "pixel56\n",
            "pixel57\n",
            "pixel82\n",
            "pixel83\n",
            "pixel84\n",
            "pixel85\n",
            "pixel111\n",
            "pixel112\n",
            "pixel139\n",
            "pixel140\n",
            "pixel141\n",
            "pixel168\n",
            "pixel196\n",
            "pixel392\n",
            "pixel420\n",
            "pixel421\n",
            "pixel448\n",
            "pixel476\n",
            "pixel532\n",
            "pixel560\n",
            "pixel644\n",
            "pixel645\n",
            "pixel671\n",
            "pixel672\n",
            "pixel673\n",
            "pixel699\n",
            "pixel700\n",
            "pixel701\n",
            "pixel727\n",
            "pixel728\n",
            "pixel729\n",
            "pixel730\n",
            "pixel731\n",
            "pixel754\n",
            "pixel755\n",
            "pixel756\n",
            "pixel757\n",
            "pixel758\n",
            "pixel759\n",
            "pixel760\n",
            "pixel780\n",
            "pixel781\n",
            "pixel782\n",
            "pixel783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_used_labels_array = np.array(non_used_labels)\n",
        "\n",
        "plt.imshow(non_used_labels_array[1:785].reshape(img_size, img_size))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zIdjH5eTAgMX",
        "outputId": "ac85f493-40ea-4a8b-f7e4-2c64b53c09eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(digits[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNOduBd4Ar6t",
        "outputId": "37c5e12a-9fad-414f-8702-6545a1396b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b14HpEj-9h0R"
      },
      "source": [
        "# Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjFAeHpz9lE4"
      },
      "source": [
        "Derive from the raw pixel data a feature that quantifies \"how much ink\" a digit costs. Report the average and standard deviation of this feature within each class. If you look at these statistics, can you see which pairs of classes can be distinguished well, and which pairs will be hard to distinguish using this feature?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ink Feature"
      ],
      "metadata": {
        "id": "1i928P6PYLN2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0cuPYGM9j-f"
      },
      "source": [
        "# create ink feature\n",
        "import numpy as np\n",
        "ink = np.array([sum(row) for row in digits])\n",
        "# compute mean for each digit class\n",
        "ink_mean = [np.mean(ink[labels == i]) for i in range(10)]\n",
        "# compute standard deviation for each digit class\n",
        "ink_std = [np.std(ink[labels == i]) for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOV5FCnbCWl3",
        "outputId": "0446cea5-92e0-4638-cd41-ce1509d828ff"
      },
      "source": [
        "for i in range(10):\n",
        "  print('Class', i, ':', 'mean:',ink_mean[i], 'std:',ink_std[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 : mean: 34632.40755082285 std: 8461.892043158483\n",
            "Class 1 : mean: 15188.466268146884 std: 4409.461697281539\n",
            "Class 2 : mean: 29871.099353603066 std: 7653.006198983366\n",
            "Class 3 : mean: 28320.188002757986 std: 7574.104535679545\n",
            "Class 4 : mean: 24232.72249508841 std: 6374.633457092554\n",
            "Class 5 : mean: 25835.920421607378 std: 7526.602988920305\n",
            "Class 6 : mean: 27734.917331399563 std: 7530.503187255003\n",
            "Class 7 : mean: 22931.244262667577 std: 6168.3408781754315\n",
            "Class 8 : mean: 30184.148412503077 std: 7777.396357381105\n",
            "Class 9 : mean: 24553.75 std: 6465.231330430596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0mgnG1d-cBQ"
      },
      "source": [
        "Using only the ink feature, fit a multinomial logit model and evaluate, by looking at the confusion matrix, how well this model can distinguish between the different classes. Since in this part of the assignment we only consider very simple models, you may use the complete data set both for training and evaluation. For example, how well can the model distinguish between the digits \"1\" and \"8\"? And how well between \"3\" and \"8\"? Scale your feature to have zero mean and unit standard deviation before you fit the multinomial logit model. You can use the function \"scale\" from \"sklearn.preprocessing\" for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsS2grMRCV7V"
      },
      "source": [
        "# The reshape is neccesary to call LogisticRegression() with a single feature\n",
        "from sklearn.preprocessing import scale\n",
        "ink = scale(ink).reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZw-y2E_8Eop"
      },
      "source": [
        "### Build model and train with ink feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T33Brj8wGAxk"
      },
      "source": [
        "# define the multinomial logistic regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model_ink = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BM6WQz7GkiW",
        "outputId": "61b1286e-b916-4481-d89c-2a051a95a71d"
      },
      "source": [
        "model_ink.fit(ink, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBph9L9J79BL"
      },
      "source": [
        "### Evaluation and Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8a0VfCj7wu7"
      },
      "source": [
        "y_pred_ink = model_ink.predict(ink)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1_36SEH77RA"
      },
      "source": [
        "from sklearn import metrics\n",
        "cnf_matrix_ink = metrics.confusion_matrix(labels, y_pred_ink)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRZNLi1y8Klw",
        "outputId": "0966f014-28c6-4e70-b743-0d77645daf8d"
      },
      "source": [
        "cnf_matrix_ink"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2420,   83,  322,  805,    0,    0,    0,  384,    0,  118],\n",
              "       [  10, 3823,    5,  101,    0,    0,    0,  722,    0,   23],\n",
              "       [1496,  280,  326, 1039,    0,    0,    0,  874,    0,  162],\n",
              "       [1247,  408,  334, 1037,    0,    0,    0, 1141,    0,  184],\n",
              "       [ 440,  831,  196,  886,    0,    0,    0, 1494,    0,  225],\n",
              "       [ 728,  672,  197,  846,    0,    0,    0, 1189,    0,  163],\n",
              "       [1057,  451,  296,  982,    0,    0,    0, 1144,    0,  207],\n",
              "       [ 325, 1194,  149,  819,    0,    0,    0, 1696,    0,  218],\n",
              "       [1430,  192,  343, 1047,    0,    0,    0,  879,    0,  172],\n",
              "       [ 484,  764,  197,  869,    0,    0,    0, 1650,    0,  224]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBJjDiw_RxJL"
      },
      "source": [
        "# Exercise 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmK3jiWgR1WJ"
      },
      "source": [
        "###New feature: Horizontal Symmetry\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvvM9gmmSA7b"
      },
      "source": [
        "Calculate the total ink of pixel 0 till 391 and divide it by the total ink, pixel 0 till 783. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLpYkxq_PZLk",
        "outputId": "1d9aa85a-05e3-46d7-fef2-81a50db53b9a"
      },
      "source": [
        "symmetry_hor = np.array([sum(row[0:392])/sum(row) for row in digits])\n",
        "print(symmetry_hor[0:6])\n",
        "\n",
        "# compute mean for each digit class\n",
        "symmetry_mean_hor = [np.mean(symmetry_hor[labels == i]) for i in range(10)]\n",
        "# compute standard deviation for each digit class\n",
        "symmetry_std_hor = [np.std(symmetry_hor[labels == i]) for i in range(10)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.50219232 0.49088749 0.43247672 0.39900166 0.50359149 0.48965786]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print('Class', i, ':', 'mean:',symmetry_mean_hor[i], 'std:',symmetry_std_hor[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-AieFub1mul",
        "outputId": "ea025661-d24e-4682-ac32-15d21fac9294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 : mean: 0.47950060172706455 std: 0.02278958843516853\n",
            "Class 1 : mean: 0.4740526720876505 std: 0.02067823055940901\n",
            "Class 2 : mean: 0.4090044242284317 std: 0.04667200220726184\n",
            "Class 3 : mean: 0.49052585297444484 std: 0.0372549734026227\n",
            "Class 4 : mean: 0.4391809742621961 std: 0.048670703268380335\n",
            "Class 5 : mean: 0.49188075199795495 std: 0.04442290593450813\n",
            "Class 6 : mean: 0.39649640050401513 std: 0.04238120919773648\n",
            "Class 7 : mean: 0.5444465902344353 std: 0.047789445545251545\n",
            "Class 8 : mean: 0.49067804545541677 std: 0.028148341308891076\n",
            "Class 9 : mean: 0.49701132048059565 std: 0.045670089562151454\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "symmetry_hor = scale(symmetry_hor).reshape(-1, 1)\n",
        "print(symmetry_hor[0:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co_gVYff0H7t",
        "outputId": "beb1345d-fa4c-4414-8b16-1299ceefe338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.52683763]\n",
            " [ 0.33157625]\n",
            " [-0.6773166 ]\n",
            " [-1.25551047]\n",
            " [ 0.55100456]\n",
            " [ 0.3103377 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(symmetry_hor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxDJm_7j8hls",
        "outputId": "a1437e1a-3b8e-42a1-d190-af4b5c6d8d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivOyMtmpeB76"
      },
      "source": [
        "###Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psrzm3XnQwS1"
      },
      "source": [
        "# define the multinomial logistic regression model\n",
        "model_symmetry_hor = LogisticRegression(multi_class='multinomial', solver='lbfgs')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ER2sRJrFa8y-",
        "outputId": "8ed1f0d9-41e9-49fa-c4b2-9b9fb7b79ac8"
      },
      "source": [
        "# train the model\n",
        "model_symmetry_hor.fit(symmetry_hor, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vmvbv7tnQ9w1"
      },
      "source": [
        "### Evaluation and Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bjL-TcMQ3TW"
      },
      "source": [
        "y_pred_symmetry_hor = model_symmetry_hor.predict(symmetry_hor)\n",
        "cnf_matrix_symmetry_hor = metrics.confusion_matrix(labels, y_pred_symmetry_hor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgmJBwrBRPfQ",
        "outputId": "4a81d437-908a-4e52-c014-b6350ffcdbf6"
      },
      "source": [
        "cnf_matrix_symmetry_hor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0, 2290,   35,  777,  383,    0,    5,  191,    0,  451],\n",
              "       [   0, 2882,   39,  865,  579,    0,    6,   67,    0,  246],\n",
              "       [   0,  614,  766,  101,  720,    0, 1885,   37,    0,   54],\n",
              "       [   0, 1406,  153,  639,  448,    0,   41, 1026,    0,  638],\n",
              "       [   0,  864,  856,  155,  892,    0,  898,  286,    0,  121],\n",
              "       [   0, 1022,  195,  475,  413,    0,   99, 1101,    0,  490],\n",
              "       [   0,  417,  751,   41,  568,    0, 2339,    5,    0,   16],\n",
              "       [   0,  280,   84,  144,  122,    0,   42, 3417,    0,  312],\n",
              "       [   0, 1506,   53,  846,  256,    0,   16,  666,    0,  720],\n",
              "       [   0, 1432,  120,  495,  467,    0,   16, 1210,    0,  448]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###New feature: Vertical Symmetry"
      ],
      "metadata": {
        "id": "LZbT2WdQ5IKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "symmetry_vert = []\n",
        "\n",
        "for row in digits:\n",
        "  sum_per_instance = 0\n",
        "  for i in range(28):\n",
        "    sum_per_instance += (sum(row[i*28:i*28+13]))\n",
        "  symmetry_vert.append(sum_per_instance/sum(row))"
      ],
      "metadata": {
        "id": "vfkGYUZf6EJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symmetry_vert = np.array(symmetry_vert)\n",
        "print(symmetry_vert.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jN3I0SW85Sa",
        "outputId": "a9562034-db6f-4597-97b5-29b5259b28bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute mean for each digit class\n",
        "symmetry_vert__mean = [np.mean(symmetry_vert[labels == i]) for i in range(10)]\n",
        "# compute standard deviation for each digit class\n",
        "symmetry_vert__std = [np.std(symmetry_vert[labels == i]) for i in range(10)]"
      ],
      "metadata": {
        "id": "hURPeFm_5Ob7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print('Class', i, ':', 'mean:',symmetry_vert__mean[i], 'std:',symmetry_vert__std[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PstGKTQk51Ct",
        "outputId": "e46fe3a6-1330-4e5b-fc21-1c82fd2411fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 : mean: 0.42655552387032253 std: 0.030982864799261725\n",
            "Class 1 : mean: 0.20998888064394558 std: 0.13183692304460393\n",
            "Class 2 : mean: 0.37359735705806796 std: 0.04051106782485404\n",
            "Class 3 : mean: 0.33824194932114043 std: 0.04449788271225449\n",
            "Class 4 : mean: 0.3781559077699028 std: 0.05338737867962625\n",
            "Class 5 : mean: 0.39090472537191384 std: 0.04555011233998501\n",
            "Class 6 : mean: 0.39066228746662696 std: 0.051346092222816185\n",
            "Class 7 : mean: 0.3285830496549184 std: 0.060907781740545425\n",
            "Class 8 : mean: 0.37307740026231584 std: 0.05214090226178142\n",
            "Class 9 : mean: 0.3382603613689483 std: 0.04851249224118977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "symmetry_vert = scale(symmetry_vert).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "rDsLfglD-Twk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Build model"
      ],
      "metadata": {
        "id": "fqq-S5T6_T6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the multinomial logistic regression model\n",
        "model_symmetry_vert = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "# train the model\n",
        "model_symmetry_vert.fit(symmetry_vert, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iQQE8H5-dPd",
        "outputId": "14c30b50-d3fc-491c-9de8-545977042516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "qNqZmnVw_WQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_symmetry_vert = model_symmetry.predict(symmetry_vert)\n",
        "cnf_matrix_symmetry_vert = metrics.confusion_matrix(labels, y_pred_symmetry_vert)"
      ],
      "metadata": {
        "id": "OMVuyItw-dRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix_symmetry_vert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OYZ3TVx-uPx",
        "outputId": "c880a267-42d0-4e5b-caab-1585ceceff01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,  230,    0,  437,    9,    0,    1, 2409,    0, 1046],\n",
              "       [   0,  692,  354,  262,  432,    0, 2661,   87,    0,  196],\n",
              "       [   0, 1721,   68,  931,  314,    0,   20,  411,    0,  712],\n",
              "       [   0, 2108,  346,  491,  946,    0,  144,   89,    0,  227],\n",
              "       [   0, 1441,  130,  579,  402,    0,   44,  874,    0,  602],\n",
              "       [   0, 1055,   45,  706,  181,    0,   27,  881,    0,  900],\n",
              "       [   0, 1176,   84,  638,  271,    0,   29, 1178,    0,  761],\n",
              "       [   0, 1313,  683,  490,  870,    0,  436,  213,    0,  396],\n",
              "       [   0, 1380,  168,  674,  411,    0,   63,  663,    0,  704],\n",
              "       [   0, 1784,  384,  443,  972,    0,  150,  160,    0,  295]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrrCcaURRWjw"
      },
      "source": [
        "# Exercise 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5imClrVRbCu"
      },
      "source": [
        "Fit a multinomial logit model using both features, and report if and how it improves on the single-feature models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zH3bEd4RxWk",
        "outputId": "418e8fd5-dba9-4f00-d2a0-b9436e9bec30"
      },
      "source": [
        "print(ink.shape)\n",
        "print(symmetry_hor.shape)\n",
        "print(symmetry_vert.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 1)\n",
            "(42000, 1)\n",
            "(42000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4unD2MJORfhs",
        "outputId": "f503a48f-6ce7-437d-b817-aa2ab78edff5"
      },
      "source": [
        "two_feature_ink_symH = np.column_stack((ink, symmetry_hor))\n",
        "print(two_feature_ink_symH.shape)\n",
        "two_feature_ink_symV = np.column_stack((ink, symmetry_vert))\n",
        "print(two_feature_ink_symV.shape)\n",
        "two_feature_symH_symV = np.column_stack((symmetry_hor, symmetry_vert))\n",
        "print(two_feature_symH_symV.shape)\n",
        "\n",
        "three_features = np.column_stack((ink, symmetry_hor, symmetry_vert))\n",
        "print(three_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42000, 2)\n",
            "(42000, 2)\n",
            "(42000, 2)\n",
            "(42000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXhr80pzdWOy"
      },
      "source": [
        "###Build models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APhCrIdqSSCD",
        "outputId": "d56ca78f-c07d-432b-fe00-aaa39a6db6f3"
      },
      "source": [
        "#Model 1\n",
        "model_2features_ink_symH = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "# train the model\n",
        "model_2features_ink_symH.fit(two_feature_ink_symH, labels)\n",
        "\n",
        "#Model 2\n",
        "model_2features_ink_symV = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "# train the model\n",
        "model_2features_ink_symV.fit(two_feature_ink_symV, labels)\n",
        "\n",
        "#Model 3\n",
        "model_2features_symH_symV = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "# train the model\n",
        "model_2features_symH_symV.fit(two_feature_symH_symV, labels)\n",
        "\n",
        "#Model 4\n",
        "model_3features = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "# train the model\n",
        "model_3features.fit(three_features, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(multi_class='multinomial')"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyLifgF1dUZV"
      },
      "source": [
        "### Evaluation and Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR8KyKqxd-wx"
      },
      "source": [
        "y_pred__ink_symH = model_2features_ink_symH.predict(two_feature_ink_symH)\n",
        "cnf_matrix__ink_symH = metrics.confusion_matrix(labels, y_pred__ink_symH)\n",
        "\n",
        "y_pred_ink_symV = model_2features_ink_symV.predict(two_feature_ink_symV)\n",
        "cnf_matrix_ink_symV = metrics.confusion_matrix(labels, y_pred_2features_ink_symV)\n",
        "\n",
        "y_pred_symH_symV = model_2features_symH_symV.predict(two_feature_symH_symV)\n",
        "cnf_matrix_symH_symV = metrics.confusion_matrix(labels, y_pred_2features_symH_symV)\n",
        "\n",
        "y_pred_3features = model_3features.predict(three_features)\n",
        "cnf_matrix_3features = metrics.confusion_matrix(labels, y_pred_3features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIpSMElOKbIR"
      },
      "source": [
        "def correct_labels_percentage(mat):\n",
        "  n = len(mat)\n",
        "  j = 0\n",
        "  correct = 0\n",
        "  for i in range(len(mat)):\n",
        "    #print(cnf_matrix_2features[i][j])\n",
        "    correct += mat[i][j]\n",
        "    j += 1\n",
        "  result = (correct/np.sum(mat))*100\n",
        "  return (result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqTz5X4jes6m",
        "outputId": "99eaed8d-6e84-4ac3-ea6d-04f827512862"
      },
      "source": [
        "cnf_matrix__ink_symH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2379,   93,  128,  737,  244,    0,    7,   48,  199,  297],\n",
              "       [  13, 3929,   10,   64,  285,    0,    3,   50,    1,  329],\n",
              "       [ 402,  132, 1323,  177,  599,    0, 1390,   22,   24,  108],\n",
              "       [ 977,  345,  214,  698,  446,    0,   40,  700,  315,  616],\n",
              "       [ 193,  537,  575,  247, 1228,    0,  782,  256,   27,  227],\n",
              "       [ 482,  539,  164,  485,  452,    0,   94,  851,  209,  519],\n",
              "       [ 258,  164, 1020,   90,  591,    0, 1939,    2,   11,   62],\n",
              "       [  94,  403,   42,  138,  162,    0,   48, 3166,  123,  225],\n",
              "       [1176,  218,  113,  884,  302,    0,    9,  286,  408,  667],\n",
              "       [ 393,  552,  129,  550,  641,    0,   19, 1071,  124,  709]])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(labels, y_pred__ink_symH)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z50fF2XdBsL-",
        "outputId": "15243453-1d24-45c4-b0d1-033f8e1b4304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is:  37.569047619047616 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix_ink_symV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB1HqcEsBWQj",
        "outputId": "e2a91389-92f4-4a84-b4e4-8caac4396397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2910,    4,  196,   57,  193,  211,  393,   22,  131,   15],\n",
              "       [   6, 3538,   11,  127,  562,   31,   24,  372,    0,   13],\n",
              "       [ 747,  117,  555,  825,  541,   94,  443,  423,  340,   92],\n",
              "       [ 218,  332,  372, 1690,  317,   33,  150,  865,  259,  115],\n",
              "       [ 603,  364,  250,  383,  925,  289,  398,  695,   59,  106],\n",
              "       [ 742,  198,  289,  286,  924,  351,  477,  365,  109,   54],\n",
              "       [1175,  196,  310,  428,  663,  270,  433,  450,  138,   74],\n",
              "       [ 162,  927,  174,  828,  715,  100,  254, 1123,   45,   73],\n",
              "       [ 973,  113,  423,  912,  392,  118,  390,  433,  221,   88],\n",
              "       [ 190,  556,  243,  939,  559,   61,  203, 1228,   79,  130]])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(labels, y_pred_ink_symV)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqGyz04mBxT6",
        "outputId": "f53ba941-0f58-41e8-941e-85cd32bea6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is:  28.27619047619048 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix_symH_symV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og_1jEJpBYm3",
        "outputId": "230a2aea-c765-4ff0-8cc7-e11a4344c5ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3023,    3,    4,   59,  346,  369,   30,   22,  265,   11],\n",
              "       [ 187, 3161,   18,  614,  303,   84,    7,   37,  224,   49],\n",
              "       [ 203,  141, 1092,  215,  696,   58, 1590,   31,  127,   24],\n",
              "       [ 117,  585,  176, 1079,  446,  201,   34,  903,  424,  386],\n",
              "       [ 557,  223,  839,  305,  752,   77,  892,  228,  141,   58],\n",
              "       [1000,  101,  140,  342,  428,  566,  157,  558,  378,  125],\n",
              "       [ 492,   66, 1030,   48,  419,   17, 2024,    0,   39,    2],\n",
              "       [ 136,  347,   75,  157,   82,  212,   30, 3148,  115,   99],\n",
              "       [ 930,  285,   36,  734,  316,  549,   28,  349,  580,  256],\n",
              "       [ 223,  426,  109,  962,  517,  171,   40, 1145,  323,  272]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26TQnf1mMwBO",
        "outputId": "11be8fb1-ad12-46c2-d01f-1db451b84030"
      },
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(labels, y_pred_symH_symV)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is:  37.37380952380953 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa6DLyvmMV21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23d48c1-216c-41bf-c2e8-c99d76536eca"
      },
      "source": [
        "cnf_matrix_3features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2934,    8,   80,   56,  195,  456,   26,    8,  348,   21],\n",
              "       [   9, 3721,   10,  159,  329,  254,    2,   42,    8,  150],\n",
              "       [ 226,   92, 1600,  242,  523,   91, 1183,   22,  121,   77],\n",
              "       [ 171,  333,  308, 1462,  264,  166,   31,  650,  502,  464],\n",
              "       [ 305,  308,  582,  186, 1192,  222,  813,  216,   88,  160],\n",
              "       [ 608,  189,  131,  234,  522,  917,  128,  481,  358,  227],\n",
              "       [ 424,   98, 1060,   40,  547,   71, 1843,    0,   33,   21],\n",
              "       [  84,  361,   74,  253,   85,  269,   28, 3003,  116,  128],\n",
              "       [ 911,  152,  102,  885,  226,  520,   19,  174,  698,  376],\n",
              "       [ 171,  450,  160,  781,  481,  281,   33, 1039,  226,  566]])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(labels, y_pred_3features)*100, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfG0nG-dCs7x",
        "outputId": "f03ef99b-f452-4624-8786-f183bfdb22a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is:  42.70476190476191 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzALkej8fJMz"
      },
      "source": [
        "###Compare with confusion matrix of ink and symmetry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzFn0FXDeyeq"
      },
      "source": [
        "cnf_matrix_ink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-KWggY3O6pq"
      },
      "source": [
        "print('Correct score of ink feature model:',correct_labels_percentage(cnf_matrix_ink),'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0qL8F-9fOt7"
      },
      "source": [
        "cnf_matrix_symmetry"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDJ8JcvSQJLX"
      },
      "source": [
        "print('Correct score of symmetry feature model:',correct_labels_percentage(cnf_matrix_symmetry),'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dIn-VlqIK5r"
      },
      "source": [
        "#Exercise 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VodgGdU1Ql0l"
      },
      "source": [
        "In this part we use the 784 raw pixel values themselves as features.\n",
        "Draw a random sample of size 5,000 from the data, and use these 5,000 examples for training and model selection (using cross-validation). Estimate the error of the models finally selected on the remaining 37,000 examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZGXfS-xIMhC"
      },
      "source": [
        "###Spli the data in 5000 traning data and 37000 test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWM27V49Ikeq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGobYOLQIXvl"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(digits, labels, test_size=37000, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWaMKXBFTi-9"
      },
      "source": [
        "##Regularized multinomial logit model (using the LASSO penalty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kKAbzNeQwgI"
      },
      "source": [
        "###Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x82g9HWQzKA"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import linear_model\n",
        "gridLR = GridSearchCV(cv=5,\n",
        "             estimator=linear_model.Lasso(),\n",
        "             param_grid={'alpha': [0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]})\n",
        "gridLR.fit(x_train, y_train)\n",
        "print(\"Initial score:\" , gridLR.best_score_)\n",
        "gridLR.best_params_\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9NbtUuIxqHd"
      },
      "source": [
        "best_param_lr = gridLR.best_params_['alpha']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE2Mpx6KyAYO"
      },
      "source": [
        "###Logistic Regression Model with Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMEf3tLDxyT3"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "clf_lr_with_lasso = Lasso(alpha= best_param_lr)\n",
        "clf_lr_with_lasso.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMF55QvT1ZNZ"
      },
      "source": [
        "y_hat = clf_lr_with_lasso.predict(x_test)\n",
        "y_hat_round = np.abs(np.round(y_hat))\n",
        "for y in range(len(y_hat_round)):\n",
        "  if y_hat_round[y] > 9:\n",
        "    y_hat_round[y] = 9\n",
        "  if y_hat_round[y] < 0:\n",
        "    y_hat_round[y] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSP5myUXceOF"
      },
      "source": [
        "###Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvY0c4yW44XN"
      },
      "source": [
        "cnf_matrix_lr_with_lasso = metrics.confusion_matrix(y_test, y_hat_round)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhgcDTsG5Pha"
      },
      "source": [
        "cnf_matrix_lr_with_lasso"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HL4qIfF2ukq"
      },
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(y_test, y_hat_round)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2Pq9ptv82oB"
      },
      "source": [
        "#SVM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVnkcektcYuA"
      },
      "source": [
        "###Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GSv84aH82B9"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "gridLR_SVM = GridSearchCV(cv=5,\n",
        "             estimator=LinearSVC(),\n",
        "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100]})\n",
        "gridLR_SVM.fit(x_train, y_train)\n",
        "print(\"Initial score:\" , gridLR_SVM.best_score_)\n",
        "gridLR_SVM.best_params_\n",
        "\n",
        "best_param_svm = gridLR_SVM.best_params_['C']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idbqXRaS82eW"
      },
      "source": [
        "###Model SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrgbZKSrABRM"
      },
      "source": [
        "clf_svm = LinearSVC(C = best_param_svm)\n",
        "clf_svm.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-ZLyX4kciQH"
      },
      "source": [
        "###Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-WKwPDrAYcI"
      },
      "source": [
        "y_pred_svm = clf_svm.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgQIMPKTAVaO"
      },
      "source": [
        "cnf_matrix_svm = metrics.confusion_matrix(y_test, y_pred_svm)\n",
        "cnf_matrix_svm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7-fN2clA5XV"
      },
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(y_test, y_pred_svm)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6iP1rcBDmP"
      },
      "source": [
        "#MLP Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZPCFZF5ckPZ"
      },
      "source": [
        "###Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uxSPkYjcmJ9"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(500,), (600,),(700,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.01, 0.025, 0.05],\n",
        "    'learning_rate': ['constant'],\n",
        "}\n",
        "griddeepnetwork = GridSearchCV(estimator=MLPClassifier(),param_grid=parameter_space,cv=5)\n",
        "griddeepnetwork.fit(x_train, y_train)\n",
        "print(\"Initial score:\" , griddeepnetwork.best_score_)\n",
        "griddeepnetwork.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVLwcDq0cgQW"
      },
      "source": [
        "Best parameters:\n",
        "\n",
        "Initial score: 0.9224\n",
        "{'activation': 'relu',\n",
        " 'alpha': 0.05,\n",
        " 'hidden_layer_sizes': (500,),\n",
        " 'learning_rate': 'constant',\n",
        " 'solver': 'adam'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGYBrW9fdMFZ"
      },
      "source": [
        "###Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GkKeG3edLKb"
      },
      "source": [
        "clf_mlp = MLPClassifier(activation= 'relu',\n",
        " alpha= 0.05,\n",
        " hidden_layer_sizes = (500,),\n",
        " learning_rate = 'constant',\n",
        " solver = 'adam')\n",
        "clf_mlp.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u_s5ol6dmxV"
      },
      "source": [
        "###Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW7uxfBFdmLd"
      },
      "source": [
        "y_pred_mlp = clf_mlp.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-N6NnIXLeDg6"
      },
      "source": [
        "cnf_matrix_mlp = metrics.confusion_matrix(y_test, y_pred_mlp)\n",
        "cnf_matrix_mlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_6163YTZM0r"
      },
      "source": [
        "print(\"Accuracy is: \",metrics.accuracy_score(y_test, y_pred_mlp)*100, \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}